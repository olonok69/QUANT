{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Instructions\n",
    "<i>You can run the notebook document sequentially (one cell at a time) by pressing <b> shift + enter</b>. While a cell is running, a [*] will display on the left. When it has been run, a number will display indicating the order in which it was run in the notebook [8].</i>\n",
    "\n",
    "<i>Enter edit mode by pressing <b>`Enter`</b> or using the mouse to click on a cell's editor area. Edit mode is indicated by a green cell border and a prompt showing in the editor area.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "\n",
    "Bagging involves creating 'N' random subsets with replacement from the training dataset and then, fitting N models, one for each of the subsets. The final prediction is the average predictions (or majority voting for classifier) of all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingRegressor\n",
    "\n",
    "We will use BaggingRegressor function from the sklearn.ensemble module to do bagging. The BaggingRegressor takes following as input parameter\n",
    "1. <b>base_estimator:</b> estimator model (regression tree)\n",
    "2. <b>n_estimators:</b> number of trees to create \n",
    "3. <b>random_state:</b> random seed\n",
    "\n",
    "You can use the help function: help(BaggingRegressor) to see the details of BaggingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=400,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base estimator\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import the BaggingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# seed is used as input to the random number generator to randomly select a subset from the training dataset\n",
    "seed = 42\n",
    "\n",
    "# Define the BaggingRegressor model\n",
    "bagging_reg = BaggingRegressor(\n",
    "        base_estimator = DecisionTreeRegressor(min_samples_leaf = 400),\n",
    "        n_estimators = 10,\n",
    "        random_state = seed\n",
    "    )\n",
    "\n",
    "bagging_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line to see details of BaggingRegressor\n",
    "# help(BaggingRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice, you can import the data, define predictors and target variable, split the data in train and test and compute the strategy returns on the dataset using bagging model and compare it with regression tree performance.\n",
    "<BR>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
