{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Instructions\n",
    "<i>You can run the notebook document sequentially (one cell at a time) by pressing <b> shift + enter</b>. While a cell is running, a [*] will display on the left. When it has been run, a number will display indicating the order in which it was run in the notebook [8].</i>\n",
    "\n",
    "<i>Enter edit mode by pressing <b>`Enter`</b> or using the mouse to click on a cell's editor area. Edit mode is indicated by a green cell border and a prompt showing in the editor area.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Hyperparameters cannot be learned by the model but need to be specified by the user before training the models. In this notebook, we will find the best hyperparameters for random forest model created in the previous section using random search and grid search cross validation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with below steps which you already know!\n",
    "1. Import the data\n",
    "2. Define predictor variables and a target variable\n",
    "3. Split the data into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('AAPL.csv')\n",
    "\n",
    "# Returns\n",
    "data['ret1'] = data.Adj_Close.pct_change()\n",
    "data['ret5'] = pd.rolling_sum(data.ret1, 5)\n",
    "data['ret10'] = pd.rolling_sum(data.ret1, 10)\n",
    "data['ret20'] = pd.rolling_sum(data.ret1, 20)\n",
    "data['ret40'] = pd.rolling_sum(data.ret1, 40)\n",
    "\n",
    "# Standard Deviation\n",
    "data['std5'] = pd.rolling_std(data.ret1, 5)\n",
    "data['std10'] = pd.rolling_std(data.ret1, 10)\n",
    "data['std20'] = pd.rolling_std(data.ret1, 20)\n",
    "data['std40'] = pd.rolling_std(data.ret1, 40)\n",
    "\n",
    "# Future returns\n",
    "data['retFut1'] = data.ret1.shift(-1)\n",
    "\n",
    "# Define predictor variables (X) and a target variable (y)\n",
    "data = data.dropna()\n",
    "predictor_list = ['ret1','ret5', 'ret10', 'ret20', 'ret40', 'std5', 'std10', 'std20', 'std40']\n",
    "X = data[predictor_list]\n",
    "y = data.retFut1\n",
    "\n",
    "# Split the data into train and test dataset\n",
    "train_length = int(len(data)*0.80)\n",
    "X_train = X[:train_length] \n",
    "X_test = X[train_length:]\n",
    "y_train = y[:train_length]\n",
    "y_test = y[train_length:]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key hyperparameters in random forest method are\n",
    "- n_estimators,\n",
    "- max_features, \n",
    "- max_depth, \n",
    "- min_samples_leaf, \n",
    "- and bootstrap.   \n",
    "\n",
    "We have defined below a range of values for each of these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': [True, False],\n",
       " 'max_depth': [2.0, 4.0, 6.0, 8.0, 10.0],\n",
       " 'max_features': [0.3, 0.47, 0.65, 0.82, 1.0],\n",
       " 'min_samples_leaf': [300, 333, 366, 400, 433, 466, 500, 533, 566, 600],\n",
       " 'n_estimators': [10, 12, 15, 17, 20]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 20, num = 5)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [round(x,2) for x in np.linspace(start = 0.3, stop = 1.0, num = 5)]\n",
    "\n",
    "# Max depth of the tree\n",
    "max_depth = [round(x,2) for x in np.linspace(start = 2, stop = 10, num = 5)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 300, stop = 600, num = 10)]\n",
    "\n",
    "# Method of selecting training subset for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Save these parameters in a dictionry\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "\n",
    "# Print the dictionary\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "The RandomizedSearchCV function from sklearn.model_selection package is used to find best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Uncomment below line to see detail about RandomizedSearchCV function\n",
    "# help(RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model to tune\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomizedSearchCV takes following parameter as input\n",
    "\n",
    "1. estimator: The base estimator model for which best hyperparameter values are found.\n",
    "2. param_distributions: Dictionary of parameter names and list of values to try.\n",
    "3. n_iter: Number of parameters that are tried to find the best values.\n",
    "4. random_state: The random seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [10, 12, 15, 17, 20], 'max_features': [0.3, 0.47, 0.65, 0.82, 1.0], 'bootstrap': [True, False], 'max_depth': [2.0, 4.0, 6.0, 8.0, 10.0], 'min_samples_leaf': [300, 333, 366, 400, 433, 466, 500, 533, 566, 600]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters by searching across 50 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = random_forest, \n",
    "                               param_distributions = param_grid, \n",
    "                               n_iter = 50,                               \n",
    "                               random_state= 42 \n",
    "                               )\n",
    "\n",
    "# Fit the model to find the best hyperparameter values\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters values for the random forest model is found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 2.0,\n",
       " 'max_features': 0.3,\n",
       " 'min_samples_leaf': 333,\n",
       " 'n_estimators': 17}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train the model created using the best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=2.0,\n",
       "           max_features=0.3, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=333, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=17, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the best model to best_random_forest\n",
    "best_random_forest = rf_random.best_estimator_\n",
    "\n",
    "# Initialize random_state to 42\n",
    "best_random_forest.random_state = 42\n",
    "\n",
    "# Fit the best random forest model on train dataset\n",
    "best_random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "\n",
    "Similarly, we can find the best model using grid search cross validation technique. Since this method is time consuming as it tries out all possible combinations, we have defined below less hyperparameters values for illustration purpose only. You may specify more values for hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': [True, False],\n",
       " 'max_features': [0.3, 0.65, 1.0],\n",
       " 'min_samples_leaf': [300, 450, 600],\n",
       " 'n_estimators': [10, 15, 20]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 20, num = 3)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [round(x,2) for x in np.linspace(start = 0.3, stop = 1.0, num = 3)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 300, stop = 600, num = 3)]\n",
    "\n",
    "# Method of selecting training subset for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code finds the best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_features': 0.3,\n",
       " 'min_samples_leaf': 300,\n",
       " 'n_estimators': 15}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Uncomment below line to see detail about GridSearchCV function\n",
    "# help(GridSearchCV)\n",
    "\n",
    "# Grid search of parameters by searching all the possible combinations\n",
    "rf_grid = GridSearchCV(estimator = random_forest, \n",
    "                               param_grid = param_grid\n",
    "                               )\n",
    "\n",
    "# Fit the model to find the best hyperparameter values\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameter values\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Practice\n",
    "\n",
    "You can try it yourself of how the random forest model created through RandomSearchCV and GridSearchCV performs on test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
